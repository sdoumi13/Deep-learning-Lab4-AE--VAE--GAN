# Deep-learning-Lab4-AE, VAE, GAN


# ğŸ“˜ Rapport de TP : ModÃ¨les GÃ©nÃ©ratifs Profonds (AE, VAE, GAN)

##  Introduction
Ce projet explore trois architectures fondamentales de l'apprentissage profond **non supervisÃ© et gÃ©nÃ©ratif**, appliquÃ©es au dataset **MNIST** (chiffres manuscrits).

L'objectif est de :
- RÃ©duire la dimensionnalitÃ© des donnÃ©es
- Structurer un espace latent
- GÃ©nÃ©rer de nouvelles donnÃ©es synthÃ©tiques

Les modÃ¨les implÃ©mentÃ©s sont :

- **AutoEncoder (AE)** : Compression et reconstruction  
- **Variational AutoEncoder (VAE)** : ModÃ©lisation probabiliste de l'espace latent  
- **Generative Adversarial Network (GAN)** : GÃ©nÃ©ration par compÃ©tition (jeu Min-Max)

---

## ğŸ› ï¸ 1. AutoEncoder (AE)

Lâ€™AutoEncoder est un rÃ©seau de neurones qui apprend une **reprÃ©sentation compressÃ©e** des donnÃ©es dâ€™entrÃ©e, puis tente de les reconstruire.

### ğŸ”§ Architecture
Dans cette implÃ©mentation, la compression est volontairement **extrÃªme**, passant de **784 dimensions** (image MNIST 28Ã—28) Ã  **2 dimensions**.

- **Encoder** :  
  `784 â†’ 256 â†’ 128 â†’ 2`

- **Bottleneck (Goulot dâ€™Ã©tranglement)** :  
  Vecteur latent de taille **2** contenant lâ€™information essentielle.

- **Decoder** :  
  `2 â†’ 128 â†’ 256 â†’ 784`

###  Analyse des RÃ©sultats
Lâ€™entraÃ®nement sur **20 Ã©poques** montre une convergence stable :

- **DÃ©but** : Loss â‰ˆ `0.0603`
- **Fin** : Loss â‰ˆ `0.0362`

 **InterprÃ©tation**  
La diminution progressive de la **MSELoss (Mean Squared Error)** indique que le modÃ¨le parvient Ã  reconstruire les chiffres avec une erreur de plus en plus faible, malgrÃ© la perte dâ€™information imposÃ©e par un espace latent trÃ¨s rÃ©duit.

---

##  2. Variational AutoEncoder (VAE)

Contrairement Ã  lâ€™AE classique, le **VAE** nâ€™encode pas une image en un point fixe, mais en une **distribution de probabilitÃ©** dÃ©finie par :

- une moyenne **Î¼**
- une variance **ÏƒÂ²**

###  Astuce de ReparamÃ©trisation
Cette technique permet la rÃ©tropropagation du gradient Ã  travers un Ã©chantillonnage alÃ©atoire.

```python
def reparameterize(self, mu, logvar):
    std = torch.exp(0.5 * logvar)
    eps = torch.randn_like(std)  # Bruit alÃ©atoire
    return mu + eps * std

 **Sans cette astuce, lâ€™entraÃ®nement du VAE serait impossible.**

---

##  Fonction de Perte (Loss)

La **loss totale du VAE** est composÃ©e de deux termes opposÃ©s :

- **Perte de reconstruction**  
  â†’ Lâ€™image reconstruite doit Ãªtre proche de lâ€™originale

- **Divergence de Kullback-Leibler (KL)**  
  â†’ Force la distribution latente Ã  suivre une loi normale  
  **ğ’©(0,1)**

---

##  Analyse des Logs

- **Loss totale** diminue (`6438 â†’ 4399`)  
  â†’ AmÃ©lioration de la reconstruction

- **KL Divergence** augmente lÃ©gÃ¨rement puis se stabilise  
  â†’ Lâ€™espace latent devient structurÃ© et exploitable

---

##  3. Generative Adversarial Network (GAN)

Le **GAN** repose sur un jeu Ã  somme nulle entre deux rÃ©seaux :

- **GÃ©nÃ©rateur (G)** : produit des images  
- **Discriminateur (D)** : distingue les vraies images des fausses

---

##  Architecture CorrigÃ©e (MNIST)

Suite Ã  une erreur de dimension, lâ€™architecture a Ã©tÃ© adaptÃ©e :

### ğŸ”¹ GÃ©nÃ©rateur
- **EntrÃ©e** : vecteur de bruit `z âˆˆ â„Â¹â°â°`
- **Sortie** : image de taille `784` (MNIST)

### ğŸ”¹ Discriminateur
- **EntrÃ©e** : image `784`
- **Sortie** : probabilitÃ© *(rÃ©elle ou fausse)*

---

##  Dynamique dâ€™EntraÃ®nement

- **Loss_D** : capacitÃ© du discriminateur Ã  dÃ©tecter les faux
- **Loss_G** : capacitÃ© du gÃ©nÃ©rateur Ã  tromper le discriminateur

---

##  Objectif

Atteindre un **Ã©quilibre de Nash** :

- Le gÃ©nÃ©rateur produit des images rÃ©alistes
- Le discriminateur prÃ©dit avec une probabilitÃ© â‰ˆ `0.5`

---

## ğŸ“Š Conclusion Technique

Ce TP met en Ã©vidence la progression de la complexitÃ© des modÃ¨les gÃ©nÃ©ratifs :

| ModÃ¨le | Avantages | Limites |
|------|----------|--------|
| **AE** | Simple, stable, efficace | GÃ©nÃ©ration limitÃ©e |
| **VAE** | Espace latent continu et structurÃ© | Images parfois floues |
| **GAN** | Images nettes et rÃ©alistes | EntraÃ®nement instable |

---

##  PrÃ©requis pour lâ€™ExÃ©cution

```bash
pip install torch torchvision matplotlib numpy
